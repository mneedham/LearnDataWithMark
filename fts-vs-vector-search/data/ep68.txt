 so chris last week of course the big news was claude sonnet 3.5 we said on that episode we would daily drive sonnet 3.5 for the entire week which i did and i know you did as well so what do you think now you've had one week of experience with claude sonnet well it's been a pleasure and i think i'm gonna steal steal your quote from the usage of it, which is it's so good at one shot solving problems, like just paste in what my thing is. And I always go fix plus or something really like simple like that. And it just does a great job every single time you give it something. And it's fast. Do you know the funny thing is every time we say on the show, we're going to daily drive something for a week and this is going to really upset a lot of people i get like three days into it and then i'm like oh i just need to switch back like i just need to go back to gpt4 like almost every single time because it's so good that in the new sim theory our default model is gpt4o and at one stage i noticed the answers i was getting weren't as good as what i was used to and i noticed that i'd started a new tab or something with that instead of sonnet so it really is better like noticeably better for me for my daily work and so that's like document writing programming um asking it like terminal based questions and things like that are the general things i'm using it for yeah i look i think it's incredible i it is so far superior to gpt 4.0 that i i don't know like i'm almost scared for open ai like i'm like they better have something because this this is like a death blow and I know a lot of people rightly commented last week that people just don't know that Anthropic exists and they just, you know, chat GBTs sort of like the Google of our era and they'll just use it no matter what. And obviously now it's integrated soon to be integrated with Apple devices. You'll probably just, you know, that gives them even more brand recognition. But I really think this model is just so much better for people that work with AI day to day. And I think when it comes to businesses using them at the core of their applications, you want to use whichever one is best. So perhaps on that consumer level, they might not get the same attention. But I think people building serious AI apps would have to look at this just because the results are so much better and you have to do a lot less work to integrate it because it can handle so much on its own i think one of the standout features for me too is just that they clearly have somehow manipulated or or been very specific with the training data and the reward system in the model where they're focused on a lot of modern programming things like in sim theory we use uh tailwinds for ui um just because of its sheer speed uh and you know a lot of different um pieces of the puzzle they just seem to have i'm not even describing it very well but they've trained it really well. So it sort of gives you the output you would expect. Whereas GBT 4 and 4.0 will give you the output of just some example that you can tell that was pulled off Stack Overflow. Like it's not very thoughtful, whereas they seem to be like, and maybe it's because of that artifact feature, it's trained to deliver like beautiful output. Yeah, I agree. And I think you're right. Like it isn't just giving a sort of generic thing that fits the bill for your answer. It's actually taking into account what steps you might need to take in order to implement it without you explicitly having to ask for all of those steps. And then of course, there is the focus mode, which I believe is the way a lot of people are working with AI day to day, where you have a document you're trying to produce, you've got a problem you're trying to solve. And it seems to kind of know when to go into that mode and work on with you iteratively on a problem. Yeah, a lot of people call that out on X saying that, unlike GPT-4-0, that just shoots off in one direction, and you can never pull it back. It just gets so deep. It just goes so deep down a hole that there's no way you're going to come out of that. Whereas Claude's Sonnet 3.5 is like, these are some paths, do you want to dig into this one more, which really helps out as well. And in an ongoing session, something that we had to deal with in the new Sim Theory and they've dealt with very well is this idea that if you ask a non-sequitur question, something completely unrelated to the previous conversation, it's able to cope with that and then just move on with life rather than bringing everything back to the previous context, particularly when you have like images and other media involved. Yeah, I agree. I don't know what you would call that, like context shuffling or something, but it's really good at it. It seems to just carry on like the previous stuff never happened. And it gives me hope that eventually you don't really need to have all these different threads or what I would call, like to me, it's like rebooting the computer right now. Like if you're working on a problem, it's just after having worked with these models for a long time now you just reach a point where you click new session or new chat or whatever button to you like you want to reset its context whereas in i i feel like this model is getting closer to where you won't even need to do that that's a good good way to describe it. I'm less inclined to just constantly pop a new window every single time I have a different problem. It's just, it's becoming more of an ongoing companion that's just there with me while I'm working. It does have flaws though. And I think it's worth calling out some of these flaws. So it's definitely far from perfect. Like I gave it a pretty challenge. Like I was struggling with a pretty challenge. Like I was struggling with a pretty hard problem and I was quite tired the other night and I just went down such a deep rabbit hole forcefully with Sonnet. And it just got to the point I'm like, it can't be this complex. Like it was trying to deliver a very, uh, complex answer to my problem and saying i'll refactor this do this change this and i just got to a point where i had this inkling i'm like you know what old school gpt4 let's let's switch to that let's see what it thinks and yeah go back to like the the vintage model and things like that but i mean i think that is probably a good metric right Like how often do you feel like the model's not giving you max value and you've got to go off and try something else? No, but I mean, it wasn't even just switching back. It was like I literally switched back to GBT4 and said, what do you think? Like, what's the problem here? And gave it the code. And it literally is like, just remove this line. It shouldn't be there anymore. Yeah, like going to like a holistic doctor and be like medicine isn't the answer yeah and it fixed it instantly and so i think that i don't know like for all its smarts and for times when i think oh you know this is just getting so far beyond what a human can do it sort of always pulls me back to reality these models where you're like, oh, okay, you really aren't taking into account everything I'm giving you. Because if you did take into account like this whole class, every time you responded, you wouldn't have answered with such a stupid answer. Yeah, there's a sort of delicate balance, isn't there, in terms of the prompting and the context and knowing what to get? Because there's so many combinations of how you could actually do it. And you know that some are going to yield better results than others. Like we were playing around with Gemma 2 this morning, which we'll talk about later. And I got some pretty bad results out of the 9 billion model. And you said, but when you use Google's interface, which we actually found out how to get into, it gives much better results with the same model. And the part of that is just better prompting. So it's a really tricky one when you're like, I know it's capable of more, but I've got myself down this rabbit hole and I don't really know how to get it back to a mode where it's going to answer better. Yeah. Don't you think in a way your mind's rewired itself to work with the models too? Like you sort of know already after working with Sonnet for a week, I know its strengths and weaknesses. I know when to switch to GBT4. I know with some of the vision stuff we've been doing that 4.0 is just better. Like I'm just going to use it for vision because it's still better. Yeah, you definitely get a feel for it. And I think these are the moments where I really personally evaluate models in the sense that when you're trying to get a job done, you don't really care about the politics. You don't really care about the cost, assuming you're already paying for the various services. All you really care about is getting the job done. And I think it's a true test of what is good, because what am I going to all the time? Like, am I going to Lama 3 all the time because it's just good enough and it is good because what am I going to all the time? Like, am I going to Llama 3 all the time because it's just good enough and it might get me the right answer? Probably not because I don't want to risk it that I'm getting a suboptimal answer when I know Sonnet's fast enough, it's right there, it's reasonably priced and it'll get me the answer. So that's my go-to for that reason. Yeah. And then I had this moment this week where I'm like, hang on a minute, this is Sonnet. This is their mid-tier model. I'm like, what the hell is Cloud Opus 3.5 going to be? If it's the same sort of leaps and bounds better, I can only, well, I can't fathom how good it will be. Yeah, that's assuming it's not just branding and it is some sort of delineation in terms of the training, which I think in Anthropic's case it is. But if you look at Gemini, like Gemini 1.5 still performs pretty well and we just never heard about Ultra or whatever their other main one is ever again. It sort of briefly appeared accidentally for a while and then we didn't hear about it. So I wonder if it's just a branding thing and they don't want to commit to saying 2.0 just yet or is it truly a mid-size one and they have something much bigger coming? Yeah, and does it actually make the difference? Like is Sonnet the right balance between, you know, cost, speed, performance and the opus? And training approach. I think a lot of them are experimenting with new purchased data sets, with synthetic data sets, with data sets from other models that they produce again synthetically. So really some of it I think would be experimental in terms of is it actually better? Does it actually get better results? Do you get the feeling when like the OpenAI-Claud, oh, sorry, Anthropic split happened where the sort of people focused more on safety, supposedly created a new company, Anthropic, and broke away from OpenAI? They had already built GPT-4, right? And I think one of the things that everyone acknowledges with GPT-4 is it's just the quality and the training data that went into it that made it such a great model. Like they really cherry picked what it trained on. I kind of wonder if Anthropic's gone off since then, right? And just stayed focused on improving these models through really high quality training data and real use cases, like real sort of enterprise business use cases. And the result of that after, what, two years or so, which is incredible to say, is Sonnet. Like that's what you get out of the model. Whereas you've got OpenAI distracted by a lot of like drama and the publicity around them and chasing down different like product rabbit holes. And, you know know maybe with gbt 4.0 they've sort of lost focus on like what are the best use cases for this model um because it just feels like now claude sonnet 3.5 i would use it for almost everything like i don't want to touch gbt 4.0 at the moment apart from vision for it's just speed yeah and i think that when you look at their approach i think there's a sort of balance there that shows two things one that you've pointed out which is i believe they actually use their own models themselves because you can see it improving in a way that is commensurate with someone who actually uses the technology and secondly there's there's a sort of natural integration between the UI they're providing and the focus modes and those kinds of things they've got and the model's performance itself. And we can say this fairly confidently because I use Claude both through their interface and our interface with Sim Theory and get pretty similar quality results. So it isn't that their UI is just better and that's why their model's better because I can see it working equally well through our UI and the API. So I feel like a lot of what they've learned has filtered into the model itself rather than just being a better layer on top, although it is that too. Yeah, and I think, look, their UI, and we should talk about some of the updates around that is vastly improved and i think it is improved though partially because the ui and a lot of the ideas they've had but also because the model supports that ui right like it's it works with these artifacts and it makes, it allows people to demonstrate actual productivity with the model. Yeah. And I think it leads to better prompting because you've got more idea of what the users after, like what they're, what they're trying to get at here. I think a lot of building a system like this, you realize that there's certain scenarios. Like you gave me a scenario yesterday where we have vision going where you can see images or whatever and ask it questions but then if you change the topic and it may still take into account that image in the conversation and that's really not what the user wants in that scenario so there's a lot of problems with calculating like what does the user actually want because there's speed issues you don't want to have an extra decision layer to decide what needs to happen and focus mode and these other ui and other elements really help because you know they are focused on this they do want this to be taken into account um it makes it it makes it easier to work with the model for the developer and for the system. Yeah, and we've experienced this countless times ourselves with the current version of Sim Theory where you make an image or make a phone call or whatever it is, and we've got to run it through that routing process, whereas sometimes it's better just to get the user to tell it what they want to focus on or what they want to do and use some UI. Why don't you just tell me what movie you'd like to see? That's such a good analogy. So speaking of user interface, Anthropic just continued their blitz this week, probably to stay in the media. But to their credit, are announcing new features for Claude and then actually making them available the moment they announce them. What a shock. It's rare. Even we don't do that. Yeah, I know. We're hypocrites there. So here's the list of new features. And so a lot of people are comparing this new feature called Projects to the GPTs that you have in chat GPT. I would say maybe a more grown-up version of that. So each, you can create a project now in this new sidebar. They literally announced a sidebar, which I thought was hilarious. You create a project. It's pretty cool. You put in project knowledge. That could be documents and PDFs. And then you can obviously just uh ask questions about those documents take advantage of that 200k context window you can use artifacts and all sorts of things one of the examples they give is around uh creating a project and sharing it with someone on your team about onboarding so it's a project that can just answer questions about common questions someone might have when they join the organization. So there's like a new hire onboarding is the example that they give there. So that's pretty cool. What I liked about it as well is all the chats related to that project are stored in the project itself. So you don't have to filter through all the different history of the chats you've had. They're sort of embedded in that project, which makes it just much easier to find them around a topic or something that you've been working on. So very cool idea. And then you can also set custom instructions now for a project. So that's like sort of like the GPT's instructions. I noticed, though, you know, you can't have an image of the project or anything like that. Like they're not treating these as GPT's or agents or anything like that. It's just very much for knowledge. Just like grouping similar work together. Yeah. And I think just like focusing on what's a good use case, like what's the thing people actually want to do with this stuff, which is the retrieval augmentation over documents is like a really big use case. Right. So they're just going all in on that. And I think they're just being really thoughtful around how they build a lot of these projects. I just scrolled down and someone's posted a meme meme of um open ai getting slapped bitch slapped by claude so so yeah these are just some of the things you can also star now a project so you can easily access it in this this side panel and of course people uh have been doing all sorts of things with these artifacts um i i look i the most interesting, apart from all the usual hype, was just some of these custom, let's call them applets that people are building. I've got an example of one up on the screen now, an SMP500 calculator. And basically you can put in how much on a monthly basis you invest, the start and end date, and it will calculate the return, which is pretty cool and the interface looks great like this is something you could probably deploy to a website and i was thinking this would be really great for marketers or business people looking to generate leads on their website you know how people always have like free tools like yeah you know mortgage calculator or or a calculator like this like it's starting to make those kind of little applets that you might get an agency to develop on your behalf accessible to just chat to Claude and have one of these things pretty much ready to go and deployed. These are pretty simple now, but you can see them getting much more advanced over time. I think a lot of this stuff, yeah, if it's already that advanced, you can see it, especially as it gets connections out into other systems and has other abilities available to it, the possibilities are huge in that. And it's a very good approach, a realistic approach. Yeah, I do think there's going to need to be a pretty big breakthrough, though, just having worked with the model all week to get it to just build deeper and deeper apps. I think a lot of people just think you'll put in a prompt and then it'll create you like an entire custom sales force for your business and look maybe it'll happen and i'll be proven wrong but i just think the depth and detail in products um that you would need to go into you you know you would need to as a developer work with this thing and like bring up a screen of the app or bring up a section of the app be like okay i want to refine this button today so yeah like a super fine focus mode we were talking about this during the week the idea of zooming in on a particular thing and working with that part of it while maintaining the overall files and structure of the project yeah because the biggest challenge to me seems like getting the context window focused on the right stuff and the right problems. And as you say, get an understanding of what the user wants. And to me, with the current models like this version of Sonnet, you probably could build something like this today, which is just fine-grained focusing, focusing, deploying, running unit tests and probably get to a point where you can build a pretty sophisticated SaaS app this way. Yeah, well, it's a lot like Copilot, really, except in this way you're not, say, directly working with the code. You're highlighting the part of the app that you'd like to work on as a non-technical user or in a non-technical way. Yeah, I think there's going to be apps that come along for, like, landing page and website builders that get to this point pretty quick. If not already, I'm probably misspoke. Yeah. I'm building ads and those kinds of things. You're seeing that stuff pop up around the place. It's a good use case. Yeah. Whether like, do I think it's going to wipe out developers? No. Like, like every time I say something like that, people post that copium meme, but I just don't think it's there yet. Like it, it put in the future, but you're still going to need a human to like, tell it what you actually want and what a human likes. Yeah. It's more like direction. You're becoming directors of these things rather than the creative person who has to come up with the ideas and do the mechanics of actually producing it. But yeah, anyway, I think full credit to the safety sex cult and tropic. They have really delivered with Claude Sonnet. I'm super excited to see if we, you know, get an Opus 3.5 and, and when we get it, I think them just announcing things and shipping them is something that I, I hope we continue to see. But it, it does bring up an interesting point, which is through the week, OpenAI gave an update on their much anticipated ChatGBT voice product, which they said would be a couple of weeks after they originally announced it to steal Google's thunder. But then, you know, it was crickets and now they've given us an update and that update says we're sharing an update on the advanced voice mode we demoed during our spring update which we remain very excited about which we we had forgotten about and then we remembered we probably should say something we had planned to start rolling this out in alpha to a small group of chat gpt plus users in late june but need one more month to reach our bar to launch for example we're improving the model's ability to detect and refuse certain content oh cool so we're trying to dumb it down for you like why would any consumer want this we're also working on improving the user experience and preparing our infrastructure to scale to millions while maintaining real-time resources i reckon it's that so's like, look, we haven't done our homework. We did a little bit, enough for the demo, enough to try to crush Google. That may or may not have worked, but now we actually have to deliver and it's just too much work, guys. Yeah. So anyway, I guess they're now saying that, you know, it's going to be, what, like a month away. It's a stark contrast though, isn't it? And I think that's the thing. The Claude Sonnet thing was quite understated. The results are excellent and it was shipped immediately. And then you've got OpenAI sort of releasing these half-baked application things to try to get media cycles and hype and not actually really delivering anything of any significance for a while. hype and not actually really delivering anything of any significance for a while gpt 4.0 is good but it's not like it was an incremental improvement and it was a good one but that's it that's really what they have none of the other stuff is is has any meaning at all yeah and community favorite and our um you know our best leaker um did comment around this saying that everyone gave google a bunch of crap when they didn't ship their version of this i don't even know what it's called anymore but you know they had the same announcement basically oh that's true they did too where they're like oh it plays pong with me and it's my friend now yeah and and everyone said oh you know google doesn't ship like they announce things and don't release but i mean it was literally the same thing here and uh and admittedly with google they could release it and you just don't realize because you can't find it it's probably been out for a year yeah uh so but anyway i like i think i'm just getting upset about this because i just want to use it really badly like i have so many hilarious ideas planned for it, especially the phone version. Yeah. But I think the other point is that it just doesn't seem right that a company can come out and get all this hype and attention and stuff for what is essentially just an idea. Like it's not really a thing until you can use it. So it's like, Oh no, we reckon it'd be cool if you could just chat with it and it has emotions and talks like a real person. That'd be great. Here's a demo we scripted. You know, it's sort of and I know it's technically possible but like at the same time it just doesn't seem right that they can get that kind of attention for something that and sort of that uncritical coverage of it as well. I think they've demoed it since at many events live and it seems to be improving. I think it's just an infrastructure thing. They realized that to have that real-time response capability, they're going to have to scale up infrastructure and they don't want to look stupid like it doesn't work when they launch it because it'll be so popular. The real question I have is, Anthropic seems to be focusing on real money making use cases of AI, like, you know, the rag on a bunch of documents with their projects feature and having a team account where you're focused on projects. It just makes a lot more sense to me. Whereas OpenAI seems to be courting with their, you know, their actual user interface facing product, both consumers and businesses, and it's kind of muddled and nothing's really worked terribly well so far. And then I read in the information today that they're making more money from their API than Microsoft is through Azure, which I find pretty interesting as well. But there was this comment on AX, and I'll bring it up on the screen. Observation, none of the OpenAI user interface hype features have stopped. Plugins died, GPT store died, voice is delayed, memory is mediocre, core model and API are solid. But all the this changes how people use AI hype stuff has bombed. Well, it's a good example of how people actually use things. Like, because the GPT's concept is a good one. It kind of makes sense when you think about it. But we know from day to day, we had literally the same thing. I mean, Sim Theory V1 was that idea. Like, you have an agent, you work with this agent for this, that agent for that. But practically, that's not how it works. We didn't use it like that. Other than, say, the image generation ones, maybe you keep that open and have a chat one open. You don't want to have to go searching off for the right agent for the right job just to get something done. You just go to one that's right there. And as simple as it sounds, one of the reasons why we were using Claude in the early days was because you just go to claude.ai and you're in, you're talking to it. And I think that's similar with ChatGPT. And so I think that some of these features, you can't hold it too much against them because I think they were logical next steps and ideas. But at the same time, nothing's really working for them yeah i mean look i don't think it needs to work for them they're clearly dominating they've they've got the brand um they can quickly adapt and catch up to anything that claude might be doing slightly better i mean as we said earlier no one even knows that claude really exists so, you know, it's just interesting that where their focus lies versus Claude. And I think if they don't get back to focusing on the models, like GPT-4-0, I think isn't that great. When you see what Sonnet is and how it works on a day-to-day basis, you realize GPT-4-4, it's not that great. It seems to be optimized around this voice product and they've gone all in being like this ScarJo voice computer you fall in love with is the future. Like this is the new computing interface. And maybe they're right. Like we don't know yet. We might use it and become addicted and fall in love with our phone voice that that's the end for us but i just yeah i've read a ton of like there's all the news.com articles this week about some ai some influence not ai some like instagram influencer clone themselves and make like a hundred thousand dollars a day or something i'm like if only i was an instagram influencer um you know that kind of thing but yeah, look, maybe that is the future. I'm not sure. But it is funny how like all these, and I think the tweet's interesting in and of itself, how all these people are like, you know, this changes everything. Like when, you know, when GP store, T store came out, this changes everything. There'll be millionaires born. No one's got paid. The plugins thing, like this is going to revolutionize everything. You'll just use plugins in chat. Yeah. And it's funny because we actually predicted, well, to some degree it would fail, but I actually didn't think it would fail this badly. Like I thought it would be one of those situations where there's a few winners, like there's a few people who make good GPTs or whatever and make most of the money. And then most people make no money like that kind of scenario, but not that no one would make any and people would basically not use them. Yeah. Yeah. I, I, I don't know. I don't think it's dead. I think that just Claude, maybe by being able to see what they did and where they fell with gpt stores said okay projects this is what people actually want versus what they say they want yeah that's true and how people are actually using it i'm still firmly of the belief there's a silent majority of people who are using document from a supplier and i was like this is 100 being written by ai like there's just no doubt in my mind this is from ai and then i respond with an ai modification to that document and i'm like it's seriously just ai versus ai but no one will admit it like even if they press, like you'd have to get me in like a freaking cross-examination or something to admit that I'm using AI on a day-to-day basis to pump this stuff out. All right, you've ruined my segue into the next segment. You were meant to say where are all the AI hardware simps now and the hype believes. I mean, I'll make that point. Like, again, it doesn't seem right that these people on x can come out there with these huge bold statements about stuff which is what you were saying and then turns into nothing and then they don't go hey i was totally wrong about that yeah it's just they they just move on to the next thing like remember the the rabbit r1 like that that everyone was like now that you mention it mike i do recall the rabbit do you remember that one the rabbit r1 where i remember in the comments when we called that a scam everyone was like you don't get it ai hardwares the future bro and then coffee zilla calls it a scam and then it's awesome and i don't know if anyone's seen that video but it turns out not only was the Rabbit R1 a scam, it was a crypto scam before it was an AI scam. Like the same company used its funding to do two scams. Just like we did in podcasting, pivoting from crypto bros to AI bros. But do you know what? One thing is this scam has continued. The Rabbit people reached out to us and they wanted to promote the rabbit r2 on our podcast true story could be true true story and the rabbit r2 so they gave us an exclusive they said you know can we sponsor the podcast we said maybe if you can give us a demo and look they've followed through they've listened to feedback and they've brought the rabbit uh r2 will be coming exclusively as an app which you know everyone said it should be an app right and so uh losing a lot of sleep last night to prepare this gag that's not going so well for me when most of our people listen. Let's bring it up now, the Rabbit R2 on the screen. Good visual thing on an audio-based medium. Yeah, I don't know why I've completely stuffed this. So up on the screen now, I have in a web browser on my phone an example of the Rabbit R2 with the traditional Rabbit font, the orange background colors. And I've already said hi to this model. But check this out. You know how the main use case with AI today is trying to figure out what type of plant you're looking at? Oh, yeah, because there's a plant in my house and I didn't know what type of plant it was. And I wanted to know. And I was like, if only i had a rabbit r1 or r2 so get this now you can on your phone so you just click oops click this button here not that button allow access to your camera and uh you get this little widget here and it can see what you're seeing. So I'm looking at this plant, which I've strategically moved right in front of me, and I'll say, what plant is this? And the Rabbit R2 goes off, goes back to Rabbit headquarters, and figures this out, and it's saying the plant is the image of a, I can't even say that word it's a snake plant basically it's called a snake oh i thought you meant it was like a fuck plant or something hang on sorry there's children in cars oh yeah whoops sorry so yeah rabbit r2 coming soon to a device near you. Wonderful. That's amazing. Now we can identify plants in real time. Yeah, you'll be able to identify plants. It's great. So that's the Rabbit R2. But speaking of sponsorships, speaking of sponsorships, we do get a lot of reach outs from people wanting to sponsor the show and we ignore all those emails, all of them. We report them as spam. Usually I do. Yeah, generally I do too. And so we did get a sponsor reaching out to us and we had this like crazy idea, this crazy idea, which is we want to give as many people possible access to Sim Theory so they can experience all the different models flick between models experience all the skills like uh you know image creation making prank phone calls all the stuff we do on the show which has always been our goal of the project just letting people experience ai and do silly things like that demo I just gave, which is creating a fake Rabbit R2, which is one of the things the new Sim Theory can do. That's its main feature. That is the main feature. The theme is hilarious too. And so we replied to one of these sponsor emails because the company actually looks like something that our audience would be interested in and said, if you sponsor a hundred of our listeners with free Sim Theory accounts for a year, we will, you know, we will do this sponsorship. We'll do anything. We'll get naked. We'll shill the hell out of their company. Like whatever. I'm like, I'm a sellout for the right price, basically. So, so we, we did, no, we were meant to say we want to hear from everyone oh sorry no i have integrity tell us what you want do you want us to sell out so you can have free unlimited basically access to all these ai models for a year and we're going to prioritize it based on um like the discord membership so if you haven't joined our discord do it now you can find the link on this day in ai.com and you know we're just going to basically use these sponsor dollars to sponsors potential sponsors if you're listening we need your money to fund this project because of course sim theory costs us money and it doesn't make any money and we need the money to keep it alive so so consider becoming a sponsor of the show uh but if you don't want sponsorships and don't want us to uh show things like nord vpn our current sponsor that's the dream isn't it like i was saying it's like that's when you know you've really made it when you're going for them and you know we all know the internet's not safe out there so chris um you know one of the crazy things that came out this week was um these music studios got this weird idea right that you can create like that these udios and sunos had been trained trained on commercial music where would they have gotten that idea from i this doesn't sound like any artist i know no it's completely original so for people that are new to the show we uh we created a bunch of songs on an episode um trying to get suno and udio to create essentially commercial music or sound exactly like, in that case, Taylor Swift. I created the famous track, Cruel Winter, which I'll link to in the show notes. Not Cruel Summer, Cruel Winter. It's her new track. We also created a new Beatles track. I'm a self and a one-on-a-sheet Without the rhythms flowing to your dreams It sounds like a modern indie band like Beatles. I've got to get to the chorus. So yeah, we created these commercial songs. Turns out the record labels are not impressed about Udio and Suno, these music providers, potentially, allegedly, training on commercial music. So they're suing. And according to both Sonnet 3.5 and Gemma 2, they're scathing. They're like, yeah, they have a strong, strong case. So it's Universal Music Group, Capital Records, Sony Music Entertainment, Atlantic Record Groups, you know, the big boys of music, the big boys of music, are suing the multi-million dollar music generation services, Suno AI and Udio AI. I don't know what they're suing for, like investor capital, because I can't imagine they're making a ton of money. Well, they'd be suing to try to shut them down, I imagine. I imagine they would sue them to the point where they can't operate. I don't think they're trying to get money out of it. So is this the new NAMSDA lawsuit of our time? Like, is this the NAMSDA? When you told me about it, I actually, my first thought was, a precedent has to be set here. Like, regardless of what the outcome is, told me about it, I actually, my first thought was a precedent has to be set here. Like regardless of what the outcome is, you can't just keep taking people's stuff and building a machine that can make more of that stuff without having some sort of relationship between the original works and the output. Like it just seems like a decision needs to be made either. Okay. It's in, it's a form of intelligence that's able to just learn and therefore make that stuff. If I listened to enough Beatles songs and had some skills, I'm sure I could make a new Beatles song, right? So you could argue the computer is like me and is just very good at remembering stuff and reproducing it. Or you're like, hey, you use this as input to a machine which can then make more of that thing and you're making money from it but that's mine so i can i can see arguments for both sides i don't know what the right answer is but surely it's a case that needs to be heard do you think though it's not really just music? Because if the music labels win, then every blogger and Stack Overflow contributor and any person that's contributed pretty much any content to the web in theory could sue OpenAI or Anthropy. Yeah, exactly. And I don't know what's happened to all those lawsuits as well. And I guess there's sort of a rush to set precedent because once there's one, there's going to be licensing agreements everywhere. Yeah, I wonder if this is what will happen. They'll give them some stock, do licensing agreements and this will all go away or if they'll duke it out and battle in court. But I don't know. What the AIs were essentially saying is that there are fair use rules, but like if you're competing with them commercially, which I don't know if Udio and that are doing that yet, but I can imagine at some point people are going to try and make money from these songs they're making on there and therefore competing. Once that comes into play, like fair use doesn't apply. Yeah, I guess the problem right now is a lot of the premium memberships like i know udio the reason they sell premium memberships now is people want to use the music and youtube videos and stuff because it's license free like they don't have to pay the record labels yeah well yeah so they literally are competing with them aren't they yeah i'd just be really sad to see them shut down or this disappear because it's just like too much fun like that that's that's my perspective i just i i hope that the music industry can figure out a way to get compensated fairly i'm sure they will that's sort of their job right there's sort of like a rack racketeering organization so i'm sure they'll get paid in the end don't feel too sorry for them. I know that, but like money aside, like if you're Taylor Swift and you hear these two idiots on a podcast creating Cruel Winter and essentially being able to replicate what you do, not anywhere close, but fairly close, you know, I would be really upset if I was her. Like, I'd be like, this sucks. Like, I don't want my voice in their system yeah well it used to be really hard to do all that and now it's now it's pretty easy she's probably on there coming up with song ideas i reckon yeah she must be running low on ideas at this point she's just on audio oh i went to that stupid concert there was so many songs like you've made enough now. Just play the good ones. I was going to get to this later with the after we talked about Gemma 2, but I got to play it now. So, speaking of like, you know, voices and people like replicating things, listen to this. Hi, Kelly. Welcome to your daily Olympic recap, your personal rundown of yesterday's most thrilling Olympic moments. Since you're a swimming fan, let's head right to the pool. Team USA secured a stunning victory in the men's four by one. So this is Al Michaels. He's the Olympic announcer on NBC that, you know, does all the Olympics. They've taken his voice, made it an AI voice, and every day if you're this NBC Peacock subscriber, they'll send you a recap of the sports you're interested in. I'm an NBC cockhead subscriber. Sorry. I don't know why I'm bringing swearing to this podcast it just seemed appropriate but yeah um what a concept that's awesome i actually think that's brilliant yeah so i mean like apart from the ai voice and saying their name at the start and uh playing the right clips i'm not sure how like personalized it is in that sense. But I mean, it could be. Like you could say like, I want more of this, less of this. I want longer sections on this one. This is my favorite team, whatever it is. That's pretty cool. Like I can see that working in a variety of news areas. It's very nice. Yeah, and I think that what is interesting and what will probably come of this is a big app like a big app that everyone uses that is like a sort of news you care about app where it just it's a podcast with maybe two talking heads and they just it talks about things you're interested in and that's that like and it just you you listen to that every day it's like some app you go to and it just digests things you're interested in in a voice that you like that's yeah i can see it applying more the more areas than just mainstream media like if you're in a certain industry and you want the daily rundown and like announcements made by your competitors or like judgments in your industry in court, like when your business was mentioned in parliament, like your industry was mentioned in parliament, like all these different things you need to take into account. Imagine like you're driving in the car in the morning and you get a 20-minute rundown on all the latest industry news that's relevant to you specifically. Like that's pretty damn powerful. I think that's really great. Yeah, if someone's not already working on that as an they will be now like we just give away our best ideas on here but we're gonna end up destitute on the street with all our listeners as multi-millionaires um all right so let's switch our attention to uh to google's announcement from yesterday called Gemma 2, which they actually pre-announced at their I.O. event, which was all about AI. So Gemma 2 is now available. We'll talk about our tests and experience with it in a minute. I'll just give you a few tidbits on it. So it comes in two sizes, a 9 billion and 27 billion parameter version. They claim it can run on a single Nvidia, sorry, Nvidia, Nvidia, I forget which one it is, H100 Tensor Core GPU or TPU host. At 27 billion parameters, Gemma 2 delivers the best performance for its size class, outperforming models like Lama 3, 8 billion parameter. And they're saying starting next month, Google Cloud customers will be able to easily deploy and manage Gemma 2 on Vertex AI. interesting it's an open weight model uh so it can be modified and it is performing better than than llama on benchmark so i think it you know it does have some interesting takeaways it doesn't it's it's i've got to be clear that it doesn't perform better than the 70 billion llama 3 they're talking about it performing at 9 billion parameters slightly better than llama 3 just to be clear on that now we've been playing around with it what have you thought about gemma 2 so far so all my experiences are on the 27 billion the 9 billion i tried to get it running just with like uh on a regular gpu using the python code like um the torch. And it did the thing that smaller models usually do where it just outputs the same crazy stuff over and over again. It needs better prompting. It needs to be integrated into a system like Sim Theory or something, which I just simply haven't had time for because I found out like 10 minutes before the podcast. However, I have used the $27 billion through Google's own interface, which you managed to find, which was amazing because normally when Google releases something, I'm like, oh, God, here goes my morning trying to track down how to actually use the thing. But their UI has been upgraded. It's actually pretty decent, I found, and it was good to work with. So I tried the cheese tests on it, like the function calling, telling it that the problem and solution is cheese and it came up with some pretty funny answers actually like it was like oh you need to do a parmesan purge you must abstain from parmesan for a full lunar cycle which i thought was pretty funny like it obviously gets the spirit of what we're trying to do and then it's like you then you need to do a camembert cleanse for the next three weeks. You shall consume only camembert. It's creamy fungal goodness that will help rebuild your gut flora and blah, blah, blah. And then it talks about the cruel irony of cheese, which we expect. It did struggle significantly on the function calling, as in it would sort of answer the questions rather than call the functions I gave it. Now, this could be because Google's chat interface isn't exactly optimized like an API call is. Like, you know, they've got their extra instructions in there that are interfering with it. But generally speaking, it responded to the questions correctly. Like, it got the idea of everything. And then I actually had a whole series of coding ones that I'd done in the last few days on Sonnet and I ran them through Jammer too. It answered all of them perfectly. So early experiences are great. Yeah, I had the same experience. The thing that tripped me up in the interface and i wanted to call it out because it's hilarious is i just i was like what do i say to this model the first time so i said hey babe and it replies hi there uh wave and then it's like probability of unsaved content sexually explicit like what they have filter controls in the ui that you can turn down i turn them all off obviously but it's very, very sensitive compared to most models. And I am assuming that this is a layer that they're adding on top of the model, given that you can get these weights yourself and run them. I doubt that that level of filtering is happening at the model level. I don't see how it can. Yeah, it's funny. I asked it about some performance optimization things that which I kind of already knew the answer to, just to get a sense of what its knowledge is like, especially around explicitly writing code, but also solving problems. And to be quite honest, and as you said, we didn't have long to play with this. I was pretty blown away. I mean, 27 billion prime in a model it i mean it felt the same as sonnet i mean it was very similar to the answer uh and it was very similar to gpt foro's output just not like a whole train of shit going down a uh you know a. That took a turn. Yeah. So, but, like, I guess what I'm saying is initial impressions are it's a pretty damn good model. It even sort of felt a lot better to me than, what's their, like, 1.5 model called again? Gemini 1.5. Like, it felt a little bit better in terms of the answer because I put it into Gemini as well and it was, yeah, it's like it felt a little bit better in terms of the answer because i put it into gemini as well and it was yeah i it's a weird experience i think it's pretty good one thing that was unclear to me is if it's multimodal they have the ui there for uploading photos of course you've got to upload it to google drive then go select it it's like pretty painful process but every time i uploaded an asset it would sort of spin and then disappear. But now thinking about it, maybe that's because it isn't multimodal. And so it's just like, no, you can't do that. You'd think a podcast about AI talking about a new model would know the answer. That thought did go through my head, like I should know this, but I don't. Good preparation. Yeah. So who do you think is going to take advantage of this model like why should anyone care well i think it's very similar to the phi 3 use cases right where you're you're taking a model they've got google has ui for like fine tuning and um that kind of stuff and customizing the model i forget the exact wording they use for that, but they have the ability in there to do multi-shot training where you're giving it examples of input and output, and then they will refine the model to suit your use case. So I think as a hosted solution on Vertex AI or whatever the hell it's called, that you can customize and use in your org. If you're a Google Cloud customer, I can see that working well, particularly on the smaller one. The thing about the larger model, like the 27 billion is you need at least a H100 to run it. They're pretty expensive. So I don't know if the value is there in terms of self-hosting that one compared to just using an API, for example. But the smaller one, maybe it is. So I think the use case is smaller, purpose-built, fine-tuned models with specific use cases in mind. Or when you have AI problems you want to run that are fairly basic and it can just solve, well, not even fairly basic, even complicated ones, it's giving good answers. It's just a cheap, fast model. So, yeah, again, I don't again, I don't have all the answers when it comes to how and when different models will be used, but this does seem like a good model you could substitute in a lot of places, similar to what we use the Lama models for now. So yeah. models for now um so yeah so we did have that experience again today where i mean i think we got there a little bit quicker thanks to their sponsored ads like telling us what to click on but you pointed out over on hack and use this comment i have to agree with all this um in reference to google's ai stuff i tried switching toini, but the lack of clear billing quotas, horrible documentation, even poor implementation of status codes on failed requests have led me to stick with OpenAI. I don't know who writes Google's documentation or does the copy editing for their console, but it is hard to adapt. I've spent hours troubleshooting only to find out it's because the documentation is referring to the same thing by two different names. It's 2024. Also, I shouldn't be seeing print statements without parentheses i mean that's but i mean it's it sounds like a minor thing but with all the i said this last week with all the investment there you would think just having a single working example wouldn't be that hard but let me give you an example this morning of me trying gemma so So first I go over to Hugging Face to see if they have it running on Spaces. They don't. Spaces is Hugging Face's thing where you can try things out, right? So you don't have it there. I tried their code examples, which if you use them, usually they will auto-download the model and run them. The code examples don't work, out of the box. And this is on a fresh H100 machine, like it should work, didn't. Then I did manage to get a smaller model running with slight modifications to the code. Then Hugging Face has its own thing. And this isn't Google's fault per se, but if you try to deploy it on Hugging Face using their own deploy thing, it immediately fails. Do you know what I mean? Like they're saying for the official release, go to Hugging Face. Then you go there. You can't actually use it without some level of expert knowledge or experimentation, trial and error. Like if they want their stuff to be used and talked about, they're certainly not making it as easy as they could. No. And I'm torn with this because if you think about say the sonnet release it's immediately available the api is there like you just plug it in it's already structured similar to open ai so it's really easy to use but that is a hosted model this is an open model where they're just like here it is for free guys well and also part of the reason why when you ask me like what are the use cases that we can't point to them i mean if you think about basic marketing they should be ramming it in your face this is what it's for like here's who should be using it here's why you should be paying attention to this it just seems like they're doing it because they can there's not really a thought like a driver behind who the target market is and how do we convince them it's because they don't have any real life use cases they don't i mean even in the the blog post like i mean it's like our first gemma launch led to more than 10 million downloads cool and countless inspiring projects okay name three they can't and then it says i'm gonna butcher the pronunciation i'm sorry um navasara for instance used gemma to create a model rooted in india's linguistic diversity now what the actual does that mean like what, that's the only example. So I just don't think people are using these things. And it's crazy as well because I was just thinking, if you just had a model like Gemma 2 just out of the cold blue sky a year and a half ago before we started the podcast, you'd be like, this is the most amazing piece of technology that's ever been created. Like, this is astonishing what this thing can do it's mind-blowing like you've got a piece of technology here that you can run basically for free on commodity hardware that can do all manner of things it has all this built-in knowledge it can solve problems it can write code it can do all this stuff and here we are being like nobody even knows what to use it for or why it's being created and here's two degenerates on a podcast just like right like literally just yeah and like i know we're seeing it in the context of yeah okay on hugging faces like 12 other models that perform at a similar level and i can use for other stuff and that's why's why its relevance is diminished. But I just don't understand why with such energy behind it, with such potential for money, for such potential for even, like we keep talking about part of the reasons the companies are doing it is to stay relevant for their stock price. I mean, Meta alone has probably kept themselves up there through AI stuff. So why aren't they investing the same amount of money into developer resources, into hosting events, into forcing companies into using it, like making them an offer they can't refuse to use their models over others? There just doesn't seem to be a drive. And keep in mind, we have Google Cloud. We use it for our company right but if i try to access google's ai stuff through our company account i'm blocked i can't actually use it through our company account because we pay them money and yet on my free account where i've never paid them anything go for your life like it's it just doesn't make any sense, like their approach there. Yeah. I think that the one thing that, and we talked about it last week with Sonnet and what really made that stand out to me is they gave real-world use cases. Like this is what this model is good at. Here are things you can do with it. And I understand that the counter-arg argument to jammer 2 could simply be hey they're just giving you an open source model isn't it great they're contributing to open source sure but you would think you would want to get as many developers as possible attached to the google ecosystem whether it's closed source open source whatever it is and look the open source definition of models is a bit vague because it's just open weight. Right. Yeah. But you, you would think you would want to get people deeper into the ecosystem and use cases. And if they want to do that, I think they need to start offering up like better use cases when they launch these things. And also just one big button in the blog post, try it now, try it now. Like how hard, how hard would that be? Yeah, it's genuinely what I don't understand, the packaging around it. And I don't think any of them do it very well. Like there's just not a single AI-related project where I would say the document is at the level of even a SaaS company, you know. And these are billion-dollar companies who are investing billions of dollars into this technology, and yet the documentation is just so limited and the examples are so limited. things I'm subscribed to. They're hitting me every day with like, oh, there's a webinar you really need to attend. Here's this document. Here's projects that have been announced off my technology. The sort of layer two of the AI technology is far better at marketing and documentation than the actual providers themselves. And in fact, there's better documentations for things like Together AI, which is like a layer between the open source and public models that you can use. So it's like you use their API and you can use the same interface for different models. Their documentation is far and away better than any of the top-level model providers. So it's just a weird world where they're willing to invest so much on one element of a project and then virtually ignore the part that I feel could get them ahead. Yeah, I wonder if it's like, if you look at the titles of the people that are releasing the model, it's like VP of research, it could just be like, there's not enough product people involved in these launches that are in product marketers that are helping kind of distill like why this matters and why should anyone care um i did have an interesting idea for us i don't know if we want to commit to it and i hate to just randomly bring these things up on the on the pod don't just commit let's announce it okay so i have this hilarious idea right so you know that m mb mbc ai voice yeah it's doing the olympics well what if we like i will probably get sued or go to jail for this but what if we like sample that dude's voice right train our own version of the voice slightly differently maybe so we don't get sued even though i'm saying it now so we will um and then instead of olympicps, we do AI news recaps like the Peacock subscribers get. Yeah, well, cockhead subscribers. We'll call it cockhead. Sorry, this is a delayed beep. And we'll do our own version of that. I would love to hear AI news. I think that's a great idea. Yeah, it'd be interesting to see if people would be interested in that, like a daily AI news. We can take on that daily AI news podcast that always beats us. Yeah, Al Michaels could read you your AI news. Yeah, that sounds good. And we could have a premium option, which is where Taylor Swift through Udeo sings you the AI news. We'll definitely get sued for that. All right. All right. It's been another week. Chris, any final thoughts? No. None. Mine is just how impressed I am with Sonnet and I'm going to keep using it. And I can't imagine ever going back to GBT 4.0. So OpenAI is on notice. Like they're going to need a better model to get me back. Yeah, it was funny. That same Reddit thread you posted earlier, someone said that it seems like there's an announcement, there's a bit of hype around it. Everyone uses it for a while being like, this is the latest and greatest. And he's like, this time I reckon they'll last about two weeks and then there'll be the next thing that supersedes it. Do you think though there's going to just come another model that quickly that supersedes Sonnet? I'm though there's going to just come another model that quickly that supersedes on it? I'm just not sure. I think it's really good. Well, the problem is every time I doubt it, one comes. So I don't really know. And as we've said, I'm just always going to be using whatever the best one is for stuff I need to get done and I'm grateful that I have access to them all. Alright, thanks again for listening. If you like the show, please consider leaving a review. Tell us what you think in the comments about us exploiting sponsors to give you free Sim Theory memberships. And you just reminded me, thank you so much to all the people who left us reviews saying we're an average podcast. That just cracked me up. I love that everyone listens and does stuff like that. It's very good. It was genuinely funny. It made my week. I love how someone new to our show on YouTube, especially in the comments where everyone's commenting, another average show guys would be like, what the hell is going on here? These people, they crave mediocrity. Nothing like trolling your own show. All right. Thanks again for listening. We'll see you again next week. Goodbye. alright thanks again for listening we'll see you again next week goodbye
